<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <title>Logitech Sustainability Assistant (2025 Prototype)</title>
    <meta name="description" content="AI Prototype for Logitech 2025 Impact Report" />
    
    <script src="https://cdn.jsdelivr.net/npm/@stlite/mountable@0.54.0/build/stlite.js"></script>
    
    <style>
      body { margin: 0; font-family: "Segoe UI", Roboto, Helvetica, Arial, sans-serif; background-color: #fcfcfc; }
      #root { height: 100vh; }
      .loading-text { 
        display: flex; flex-direction: column; justify-content: center; align-items: center; 
        height: 100vh; color: #2d3436; font-weight: 500; letter-spacing: 1px;
      }
      .loader {
        border: 3px solid #f3f3f3; border-top: 3px solid #00B8FC; border-radius: 50%;
        width: 50px; height: 50px; animation: spin 0.8s linear infinite; margin-bottom: 20px;
      }
      @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
  </head>
  <body>
    <div id="root">
      <div class="loading-text">
        <div class="loader"></div>
        <div>INITIALIZING PROTOTYPE...</div>
      </div>
    </div>

    <script>
      stlite.mount({
        requirements: ["streamlit"],
        entrypoint: "app.py",
        files: {
          "app.py": `
import streamlit as st
import time

# --- 1. PAGE CONFIG ---
st.set_page_config(
    page_title="LogiSustainability Assistant",
    page_icon="üå±",
    layout="wide"
)

# --- 2. CUSTOM STYLING ---
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
    html, body, [class*="css"] { font-family: 'Inter', sans-serif; }
    h1 { color: #2d3436; font-weight: 700; letter-spacing: -1px; }
    h3 { color: #00B8FC; text-transform: uppercase; font-size: 14px; letter-spacing: 1px; font-weight: 700; }
    .stChatInput { border-radius: 15px !important; border: 1px solid #dfe6e9; }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .block-container { padding-top: 2rem; max-width: 1000px; }
    </style>
""", unsafe_allow_html=True)

# --- 3. HERO SECTION ---
col1, col2 = st.columns([3, 2])

with col1:
    st.markdown("### DfS ENGINEERING PROTOTYPE")
    st.title("Design for Sustainability AI")
    st.markdown("""
    **Accelerating Green Innovation.**
    This prototype demonstrates how AI can help R&D teams instantly navigate the **2025 Impact Report** to find LCA data, CarbonClarity‚Ñ¢ metrics, and material targets.
    """)
    
    m1, m2, m3 = st.columns(3)
    m1.metric("Report Year", "2025", "Latest")
    m2.metric("Data Source", "Logitech DfS", "Verified")
    m3.metric("Model Mode", "RAG Inference", "Simulated")

with col2:
    st.image("https://images.unsplash.com/photo-1451187580459-43490279c0fa?q=80&w=1000&auto=format&fit=crop", 
             caption="Visualizing Global Impact Data", use_container_width=True)

st.divider()

# --- 4. SIMULATED KNOWLEDGE BASE ---
# NOTE: No backticks used inside these strings to prevent JS errors
knowledge_base = {
    "carbonclarity": (
        "### üè∑Ô∏è CarbonClarity‚Ñ¢ Update (2025)\\n\\n"
        "**The Goal:** Radical Transparency.\\n"
        "We have expanded our carbon labeling program to include the entire enterprise portfolio. "
        "Engineers can now access the 'kg CO2e' impact for every component in the BOM (Bill of Materials). "
        "This allows for real-time carbon trade-off decisions during the prototyping phase."
    ),
    "next life plastics": (
        "### ‚ôªÔ∏è Next Life Plastics (PCR)\\n\\n"
        "**The Goal:** Circularity at Scale.\\n"
        "In 2025, Logitech aims to use >50% Post-Consumer Recycled (PCR) plastic in all mouse and keyboard lines. "
        "Current engineering guidelines prioritize recycled ABS and Polycarbonate over virgin fossil-fuel plastics "
        "to lower the 'Material Extraction' carbon footprint."
    ),
    "dfs": (
        "### ‚öôÔ∏è Design for Sustainability (DfS)\\n\\n"
        "**The Goal:** Low-Power, High-Impact.\\n"
        "DfS principles are now mandatory in the NPI (New Product Introduction) process. "
        "Key focus areas for 2025:\\n"
        "* **Low-Power ICs:** Selecting microcontrollers with ultra-low sleep currents.\\n"
        "* **Dematerialization:** Reducing PCB size and removing unnecessary weight."
    ),
    "default": (
        "**System Status: Ready.**\\n\\n"
        "I am currently connected to the **2025 Impact Report** database (Simulated). "
        "I can retrieve technical targets for:\\n"
        "* **CarbonClarity‚Ñ¢**\\n"
        "* **Next Life Plastics**\\n"
        "* **Design for Sustainability (DfS)**"
    )
}

def get_simulated_response(prompt):
    p = prompt.lower()
    if "carbon" in p or "clarity" in p: return knowledge_base["carbonclarity"]
    if "plastic" in p or "recycle" in p or "next life" in p: return knowledge_base["next life plastics"]
    if "dfs" in p or "design" in p or "lca" in p: return knowledge_base["dfs"]
    return knowledge_base["default"]

# --- 5. CHAT INTERFACE ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hello. I'm your DfS Assistant. Ask me about **CarbonClarity** or **Next Life Plastics** targets."}
    ]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Search the 2025 Impact Report..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        with st.spinner("Analyzing vectors..."):
            time.sleep(1.0) 
        
        response_text = get_simulated_response(prompt)
        
        full_response = ""
        for chunk in response_text.split():
            full_response += chunk + " "
            time.sleep(0.04)
            message_placeholder.markdown(full_response + "‚ñå")
        message_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})
`
        }
      },
      document.getElementById("root")
    );
    </script>
  </body>
</html>